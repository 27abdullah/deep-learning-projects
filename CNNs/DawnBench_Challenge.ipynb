{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO2qM3+sNF+d0MXsqo5udmE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# DawnBench Challenge"],"metadata":{"id":"T6K5HZ9qwouQ"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion * planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion * planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","def ResNet18():\n","    return ResNet(BasicBlock, [2,2,2,2])\n","\n","if __name__ == \"__main__\":\n","    start = time.time()\n","\n","    #Device configuration\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    if not torch.cuda.is_available():\n","        print(\"CUDA is not available. Training on CPU...\")\n","\n","\n","    #Load data and model\n","    transform_train = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomCrop(32, padding=4, padding_mode='reflect')\n","    ])\n","\n","    transform_test = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","    ])\n","\n","    trainset = torchvision.datasets.CIFAR10(\n","        root='./data/',\n","        train=True,\n","        transform=transform_train,\n","        download=True)\n","\n","    train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)\n","\n","    testset = torchvision.datasets.CIFAR10(\n","        root='./data/',\n","        train=False,\n","        transform=transform_test,\n","        download=True)\n","\n","    test_loader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=8)\n","\n","\n","    model = ResNet18()\n","    model =model.to(device)\n","\n","    if device.type == 'cuda':\n","        print(torch.cuda.get_device_name(0))\n","\n","    print(\"Model No. of parameters: \", sum(param.nelement() for param in model.parameters()))\n","    print(model)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n","\n","    #Piecewise linear schedule\n","    total_step = len(train_loader)\n","    sched_linear_1 = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.005, max_lr=0.1, step_size_up=15, step_size_down=15, mode=\"triangular2\")\n","    sched_linear_3 = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.005/0.1, end_factor=0.005/0.1, verbose=False)\n","    scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[sched_linear_1, sched_linear_3], milestones=[30])\n","\n","    num_epochs = 35\n","    model.train()\n","    print(\"> Training the model\")\n","    for epoch in range(num_epochs):\n","\n","        for i, (images, labels) in enumerate(train_loader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            #Forward pass\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            #Backward and optimize\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            if (i+1) % 100 == 0:\n","                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.5f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","\n","        scheduler.step()\n","\n","\n","    # Test the model\n","    print(\"Testing the model\")\n","    model.eval()\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for images, labels in test_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","        print('Test Accuracy {} %'.format(100 * correct / total))\n","\n","    end = time.time()\n","    length = end - start\n","    print(\"It took\", length / 60, \"mins!\")"],"metadata":{"id":"Zryv0X4xp9yG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725104032354,"user_tz":-600,"elapsed":1440208,"user":{"displayName":"Abdullah Badat","userId":"09370973518789664316"}},"outputId":"9879f0b0-8e05-4bea-a630-9f616f0b1afb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Tesla T4\n","Model No. of parameters:  11173962\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (linear): Linear(in_features=512, out_features=10, bias=True)\n",")\n","> Training the model\n","Epoch [1/35], Step [100/391], Loss: 1.56443\n","Epoch [1/35], Step [200/391], Loss: 1.36281\n","Epoch [1/35], Step [300/391], Loss: 1.27755\n","Epoch [2/35], Step [100/391], Loss: 1.06689\n","Epoch [2/35], Step [200/391], Loss: 1.09374\n","Epoch [2/35], Step [300/391], Loss: 0.96213\n","Epoch [3/35], Step [100/391], Loss: 0.82725\n","Epoch [3/35], Step [200/391], Loss: 0.82546\n","Epoch [3/35], Step [300/391], Loss: 0.55481\n","Epoch [4/35], Step [100/391], Loss: 0.73608\n","Epoch [4/35], Step [200/391], Loss: 0.65219\n","Epoch [4/35], Step [300/391], Loss: 0.58430\n","Epoch [5/35], Step [100/391], Loss: 0.43518\n","Epoch [5/35], Step [200/391], Loss: 0.65252\n","Epoch [5/35], Step [300/391], Loss: 0.66883\n","Epoch [6/35], Step [100/391], Loss: 0.50078\n","Epoch [6/35], Step [200/391], Loss: 0.49966\n","Epoch [6/35], Step [300/391], Loss: 0.70917\n","Epoch [7/35], Step [100/391], Loss: 0.36149\n","Epoch [7/35], Step [200/391], Loss: 0.56097\n","Epoch [7/35], Step [300/391], Loss: 0.68051\n","Epoch [8/35], Step [100/391], Loss: 0.36588\n","Epoch [8/35], Step [200/391], Loss: 0.33745\n","Epoch [8/35], Step [300/391], Loss: 0.46142\n","Epoch [9/35], Step [100/391], Loss: 0.38114\n","Epoch [9/35], Step [200/391], Loss: 0.41910\n","Epoch [9/35], Step [300/391], Loss: 0.38461\n","Epoch [10/35], Step [100/391], Loss: 0.49220\n","Epoch [10/35], Step [200/391], Loss: 0.42312\n","Epoch [10/35], Step [300/391], Loss: 0.50214\n","Epoch [11/35], Step [100/391], Loss: 0.31019\n","Epoch [11/35], Step [200/391], Loss: 0.25505\n","Epoch [11/35], Step [300/391], Loss: 0.35421\n","Epoch [12/35], Step [100/391], Loss: 0.41351\n","Epoch [12/35], Step [200/391], Loss: 0.41836\n","Epoch [12/35], Step [300/391], Loss: 0.38124\n","Epoch [13/35], Step [100/391], Loss: 0.31675\n","Epoch [13/35], Step [200/391], Loss: 0.32901\n","Epoch [13/35], Step [300/391], Loss: 0.23728\n","Epoch [14/35], Step [100/391], Loss: 0.23860\n","Epoch [14/35], Step [200/391], Loss: 0.28433\n","Epoch [14/35], Step [300/391], Loss: 0.45791\n","Epoch [15/35], Step [100/391], Loss: 0.42281\n","Epoch [15/35], Step [200/391], Loss: 0.27342\n","Epoch [15/35], Step [300/391], Loss: 0.29096\n","Epoch [16/35], Step [100/391], Loss: 0.30137\n","Epoch [16/35], Step [200/391], Loss: 0.38702\n","Epoch [16/35], Step [300/391], Loss: 0.27276\n","Epoch [17/35], Step [100/391], Loss: 0.21340\n","Epoch [17/35], Step [200/391], Loss: 0.24724\n","Epoch [17/35], Step [300/391], Loss: 0.33415\n","Epoch [18/35], Step [100/391], Loss: 0.21921\n","Epoch [18/35], Step [200/391], Loss: 0.30222\n","Epoch [18/35], Step [300/391], Loss: 0.26259\n","Epoch [19/35], Step [100/391], Loss: 0.25496\n","Epoch [19/35], Step [200/391], Loss: 0.13283\n","Epoch [19/35], Step [300/391], Loss: 0.32888\n","Epoch [20/35], Step [100/391], Loss: 0.32001\n","Epoch [20/35], Step [200/391], Loss: 0.32596\n","Epoch [20/35], Step [300/391], Loss: 0.27710\n","Epoch [21/35], Step [100/391], Loss: 0.22737\n","Epoch [21/35], Step [200/391], Loss: 0.19710\n","Epoch [21/35], Step [300/391], Loss: 0.23657\n","Epoch [22/35], Step [100/391], Loss: 0.24642\n","Epoch [22/35], Step [200/391], Loss: 0.24677\n","Epoch [22/35], Step [300/391], Loss: 0.33095\n","Epoch [23/35], Step [100/391], Loss: 0.21325\n","Epoch [23/35], Step [200/391], Loss: 0.14559\n","Epoch [23/35], Step [300/391], Loss: 0.22049\n","Epoch [24/35], Step [100/391], Loss: 0.14449\n","Epoch [24/35], Step [200/391], Loss: 0.18070\n","Epoch [24/35], Step [300/391], Loss: 0.25354\n","Epoch [25/35], Step [100/391], Loss: 0.20322\n","Epoch [25/35], Step [200/391], Loss: 0.29930\n","Epoch [25/35], Step [300/391], Loss: 0.15803\n","Epoch [26/35], Step [100/391], Loss: 0.10403\n","Epoch [26/35], Step [200/391], Loss: 0.12474\n","Epoch [26/35], Step [300/391], Loss: 0.11503\n","Epoch [27/35], Step [100/391], Loss: 0.12525\n","Epoch [27/35], Step [200/391], Loss: 0.07539\n","Epoch [27/35], Step [300/391], Loss: 0.20390\n","Epoch [28/35], Step [100/391], Loss: 0.16328\n","Epoch [28/35], Step [200/391], Loss: 0.10836\n","Epoch [28/35], Step [300/391], Loss: 0.15225\n","Epoch [29/35], Step [100/391], Loss: 0.08352\n","Epoch [29/35], Step [200/391], Loss: 0.15682\n","Epoch [29/35], Step [300/391], Loss: 0.10498\n","Epoch [30/35], Step [100/391], Loss: 0.10464\n","Epoch [30/35], Step [200/391], Loss: 0.08879\n","Epoch [30/35], Step [300/391], Loss: 0.06890\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [31/35], Step [100/391], Loss: 0.05417\n","Epoch [31/35], Step [200/391], Loss: 0.03442\n","Epoch [31/35], Step [300/391], Loss: 0.05735\n","Epoch [32/35], Step [100/391], Loss: 0.04687\n","Epoch [32/35], Step [200/391], Loss: 0.02921\n","Epoch [32/35], Step [300/391], Loss: 0.06616\n","Epoch [33/35], Step [100/391], Loss: 0.02607\n","Epoch [33/35], Step [200/391], Loss: 0.01184\n","Epoch [33/35], Step [300/391], Loss: 0.07120\n","Epoch [34/35], Step [100/391], Loss: 0.02104\n","Epoch [34/35], Step [200/391], Loss: 0.01821\n","Epoch [34/35], Step [300/391], Loss: 0.01530\n","Epoch [35/35], Step [100/391], Loss: 0.02908\n","Epoch [35/35], Step [200/391], Loss: 0.03113\n","Epoch [35/35], Step [300/391], Loss: 0.01784\n","Testing the model\n","Test Accuracy 93.74 %\n","It took 23.995293013254802 mins!\n"]}]}]}